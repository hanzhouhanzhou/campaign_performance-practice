# ğŸ“Š Marketing Analyst Interview â€” Real Home Assignment (Data-Driven Notes)

# ğŸ Python Analysis + ğŸ“Š Power BI Dashboard

The campaign performance was analyzed using **Python** (for data cleaning, KPI calculation, and segment diagnostics), and the **most actionable insights are presented in this Power BI dashboard**:

ğŸ‘‰ https://app.powerbi.com/view?r=eyJrIjoiYmIwZTZlMTYtMmZmZC00YTlhLTkyNjgtNTkxZWU1ZTM5OTUxIiwidCI6IjE2ZGVlZGU4LTc5ZTktNGUzMy05OWU2LTlkOGQzOTQyZDc5NiIsImMiOjEwfQ%3D%3D


---

## 0) ğŸ“‚ Dataset & Source

- **Notion source page:**  
  https://ruby-dryosaurus-4a2.notion.site/Marketing-Analyst-Interview-Real-Home-Assignment-6afdf1a0a6744d7bac44e138e47000d3


---

# 1) ğŸ§¹ Data Understanding & Cleaning

## ğŸ§¾ Dataset structure (Python-verified)
- **Main data:** `101,639 rows Ã— 10 columns`
- **Geo mapping:** `18,923 rows Ã— 4 columns`
- After merge (`Hotel_ID` join): **101,639 rows Ã— 13 columns**

## ğŸ§© Key fields (what each column means)
### â± Time / Entity
- **Week**: weekly reporting key (e.g., `2023/36`, `2024/08`)
- **Hotel_ID**: unique hotel identifier
- **Device**: device segment (Desktop / Mobile / Tablet)

### ğŸ“ˆ Marketing performance
- **Clicks**: traffic volume
- **Bookings**: conversions (final outcome)
- **Revenue**: attributed revenue
- **Cost**: ad spend
- **CPC**: cost per click (provided)
- **Click Value**: value attributed per click (provided)
- **Average Booking**: average value per booking (provided)

### ğŸŒ Geo fields (from mapping)
- **Country**, **Region**, **Super Region**

## âœ… Data quality checks & issues noticed (Python-verified)
- **Missing values**
  - **Average Booking** has **99,648 missing** â†’ this is expected because many rows have **Bookings = 0**, so average booking value is undefined.
  - **Hotel_ID** has **62 missing** â†’ these rows cannot be mapped/attributed to a hotel and should be excluded from hotel-level optimization.
  - Geo fields missing after join: **Country/Region/Super Region each 299 missing** â†’ hotels not found in mapping or missing `Hotel_ID`.

- **Outliers / anomalies (important for optimization)**
  - Many hotel-week-device rows have **spend but zero bookings/revenue** (common in marketing data).  
  - At **hotel aggregated level**, there are high-spend hotels with **very low ROAS**, which are true inefficiencies (see section 2.4).

## ğŸ§  Assumptions (stated clearly)
- **ROAS = Revenue / Cost**, **Profit = Revenue âˆ’ Cost**
- **CVR = Bookings / Clicks**, **CPA = Cost / Bookings**
- For ratios, **division by zero** is treated as `NaN` (not forced to 0), to avoid misleading metrics.

---

# 2) ğŸ” Exploratory Analysis (Python-driven insights)

## â­ 2.1 Overall performance (all data)
From Python aggregation:

- ğŸ’° **Total Revenue:** **67,983.3**
- ğŸ’¸ **Total Cost:** **68,023.5**
- ğŸ’µ **Total Profit:** **-40.2** *(near break-even)*
- ğŸ“ˆ **ROAS:** **0.999**
- ğŸ–± **Clicks:** **164,925**
- ğŸ“¦ **Bookings:** **2,120**
- ğŸ¯ **CVR:** **1.29%**
- ğŸ§¾ **CPA:** **32.09** per booking

âœ… **Interpretation:** The portfolio-wide result is **basically break-even**, but performance varies strongly across segments (device/geo/hotel).

---

## ğŸ† 2.2 Which devices perform best?
Python segment summary:

### ğŸ“± Device KPI table (aggregated)
- **Desktop**
  - **ROAS 1.035**, **Profit +1,746.5**
  - **CVR 1.45%**, **CPA 30.34**
  - Largest scale: **113,749 clicks / 1,648 bookings**

- **Mobile**
  - **ROAS 1.146 (highest)**, **Profit +451.3**
  - **CVR 0.84%**, **CPA 25.72**
  - Smaller scale: **14,293 clicks / 120 bookings**

- **Tablet**
  - **ROAS 0.850**, **Profit -2,238.0 (worst)**
  - **CPA 42.45 (highest)**

âœ… **Conclusion:**  
- **Best efficiency:** **Mobile** (highest **ROAS**)  
- **Best overall contributor:** **Desktop** (largest profit + scale)  
- **Underperformer:** **Tablet** (low ROAS + negative profit)

---

## ğŸŒ 2.3 Which regions perform best?
Python Super Region results (aggregated):

- ğŸ¥‡ **EastEurope:** **ROAS 1.269**, **Profit +931.0**
- ğŸ¥ˆ **NorthAmerica:** **ROAS 1.069**, **Profit +495.8** *(but **CPA 61.63** â†’ expensive bookings)*
- ğŸ¥‰ **WestEurope:** **ROAS 1.008**, **Profit +394.0** *(largest scale: **121,100 clicks / 1,682 bookings**)*

ğŸš¨ Underperforming regions:
- **MENA:** **ROAS 0.699**, **Profit -1,079.7**
- **Asia:** **ROAS 0.706**, **Profit -852.8**
- **Oceania:** **ROAS 0.773**, **Profit -104.5**

âœ… **Conclusion:**  
- **Scale + stability:** WestEurope (near break-even but huge volume)  
- **Best ROI growth candidate:** EastEurope  
- **Budget caution:** MENA / Asia (structural inefficiency)

---

## ğŸ¨ 2.4 Which hotels perform best (and where are inefficiencies)?
To avoid â€œnoiseâ€ from tiny-spend hotels, I filtered to **hotels with Cost â‰¥ 100**:

- **High-spend hotels:** **43**
- **Losing hotels (ROAS < 1):** **26**
- These losing hotels account for **66.4% of high-spend Cost**

âœ… **This is the key efficiency issue:**  
Most meaningful spend is concentrated in hotels that do **not** return revenue efficiently.

### ğŸ¥‡ Top profit hotels (Cost â‰¥ 100)
Examples (profit leaders):
- **Hotel 18175 (US):** Profit **+593.1**, ROAS **4.33**
- **Hotel 18455 (US):** Profit **+520.1**, ROAS **3.25**
- **Hotel 7472 (UK):** Profit **+463.4**, ROAS **4.27**, **CVR 3.55%**
- **Hotel 16020 (NL):** Profit **+275.4**, ROAS **2.10**, **CPA 10.44** *(excellent cost efficiency)*

### ğŸš¨ Worst efficiency hotels (Cost â‰¥ 100)
Many worst hotels show **spend with zero revenue**:
- **Hotel 6096 (Finland):** Cost **254.5**, Revenue **0**, ROAS **0**
- **Hotel 10852 (Italy):** Cost **111.3**, Revenue **0**, ROAS **0**
- **Hotel 59 (UAE):** Cost **112.9**, Revenue **0**, ROAS **0**

âœ… **Conclusion:**  
The biggest optimization lever is **hotel-level budget reallocation**: scale top-ROAS hotels and aggressively fix/pause zero-revenue spend.

---

## ğŸ”— 2.5 Relationship between Cost, Clicks, Bookings, Revenue
### ğŸ“Œ Weekly-level correlation (26 weeks)
- **Cost â†” Clicks:** **0.98** (spend drives traffic strongly)
- **Bookings â†” Revenue:** **0.91** (bookings drive value strongly)
- **Cost â†” Revenue:** **0.74** (spend increases revenue, but not perfectly)

### ğŸ“Œ Hotel-level correlation (high-spend hotels only)
- **Cost â†” Bookings:** **0.11** *(weak!)*
- **Cost â†” Revenue:** **0.25** *(weak)*
- **Revenue â†” Profit:** **0.84** *(strong)*

âœ… **Conclusion:**  
At a hotel level, more spend does **not reliably buy** more bookings/revenue â†’ this indicates **allocation inefficiency** and inconsistent conversion performance across hotels.

---

## ğŸ•’ 2.6 Patterns over time (by week)
- Total weeks observed: **26** (from **2023/36 â†’ 2024/08**)
- **Average weekly ROAS:** **1.026**
- **ROAS volatility:** std **0.286**

### ğŸŸ¢ Best week
- **2023/36:** ROAS **1.94**, Profit **+2,102.1**, CPA **21.10**

### ğŸ”´ Worst week
- **2023/45:** ROAS **0.54**, Profit **-1,442.7**, CPA **46.47**

âœ… **Conclusion:**  
Performance is **volatile week-to-week**, so decisions should be based on **rolling trends** and **consistent segment performance**, not single-week spikes.

---

# 3) ğŸ“Š Visualization (what I built & how it supports decisions)

âœ… I delivered an interactive **Power BI dashboard** (slicers + KPI cards + trends + Top-N charts).  
Key visuals include:

- ğŸ“Œ **KPI Cards:** Revenue / Bookings / Cost / ROAS  
- ğŸ© **Revenue by Device**  
- ğŸ“‰ **Profit Trend by Week**  
- ğŸ“ˆ **ROAS Trend by Week**  
- ğŸ§± **Top Countries by Revenue (Top 8)**  
- ğŸ«§ **Cost vs Revenue by Hotel** *(inefficiency detection)*

ğŸ¯ **Why this works for a Marketing Director**
- **Time to See:** KPI cards show health instantly  
- **Time to Understand:** trends explain stability/volatility  
- **Time to Act:** hotel scatter identifies where to cut or scale budget

---

# 4) âœ… Recommendations (actionable, business-first)

## 1) ğŸ§¯ Cut waste: create a â€œHotel Inefficiency Watchlistâ€
- Weekly flag hotels with **Cost â‰¥ 100** and **ROAS < 1**
- Python shows **26/43** high-spend hotels are losing, consuming **66.4%** of high-spend budget  
âœ… **Impact:** fastest ROAS improvement by removing structural loss-makers

## 2) ğŸš€ Reallocate to proven winners (scale what works)
- Scale **Desktop** (largest profit contributor)  
- Test-scale **Mobile** (highest ROAS but low volume)  
- Reduce **Tablet** (ROAS 0.85, Profit -2,238)
âœ… **Impact:** better growth with controlled risk

## 3) ğŸŒ Geo strategy: shift budget toward high-ROAS regions
- Invest more in **EastEurope (ROAS 1.27)**  
- Maintain but optimize **WestEurope** (largest scale; near break-even)  
- Tighten or restructure **MENA / Asia** (ROAS ~0.70; large negative profit)
âœ… **Impact:** improve profitability without reducing total spend

## 4) ğŸ§ª Stabilize volatility with a â€œbaseline + test budgetâ€ structure
- Separate campaigns into:
  - **Baseline** (stable segments/hotels)
  - **Test** (new hotels/regions/devices) with budget caps
âœ… **Impact:** avoids repeating â€œworst weekâ€ patterns (e.g., ROAS 0.54 in 2023/45)

## 5) ğŸ” Audit tracking where spend generates zero revenue
- Several high-spend hotels show **Revenue = 0** (ROAS 0)  
- Validate tracking, attribution window, feed/inventory issues
âœ… **Impact:** prevents spending based on broken measurement

---

## ğŸ§¾ Executive Summary (1 sentence)
**Overall ROAS is near break-even (0.999), but performance is highly uneven: Desktop drives most profit, Mobile is most efficient, Tablet loses money, and a majority of high-spend hotel budget sits in ROAS<1 hotelsâ€”so next quarterâ€™s fastest win is reallocating hotel budgets toward proven winners and high-ROAS regions while cutting zero-revenue spend.**

